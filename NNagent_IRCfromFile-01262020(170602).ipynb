{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twoboxCol import *\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import random_projection\n",
    "\n",
    "import os\n",
    "path = os.getcwd()\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# pdf.fontype and ps.fontype must be set to 42 in order for text in exported figure to be editable in Adobe Illustrator\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"CMU Serif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "color code for color cues\n",
    "\"\"\"\n",
    "rgb = [[255, 0, 0],\n",
    "       [255/4*3, 0, 255/4*1],\n",
    "       [255/4*2, 0, 255/4*2],\n",
    "       [255/4*1, 0, 255/4*3],\n",
    "       [0, 0, 255]\n",
    "      ] \n",
    "rgb=np.array(rgb)/255.\n",
    "\n",
    "cmap_col5 = mpl.colors.ListedColormap(rgb,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import agent data and IRC result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of the files\n",
    "datestring_data = '01262020(150900)'\n",
    "datestring_train = '01262020(151953)'\n",
    "datestring_NNagent='01262020(170602)'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "datestring_IRC = '01262020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zhengwei/Dropbox/BCM/_Code/inversePOMDP/IRC_TwoSiteForaging/Results/01262020(151953)_data01262020(150900)_agentNN01262020(170602)_01262020IRC0_twoboxCol.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1f335485e390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIRC\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mincluding\u001b[0m \u001b[0mtrjectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m dataN_pkl_file_IRC = open(path + '/Results/' + datestring_train + '_data' + datestring_data +  \n\u001b[0m\u001b[1;32m      5\u001b[0m                    '_agentNN' + datestring_NNagent + '_' + datestring_IRC + 'IRC'+ str(idx) +'_twoboxCol' + '.pkl', 'rb')\n\u001b[1;32m      6\u001b[0m \u001b[0mdataN_pkl_IRC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataN_pkl_file_IRC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zhengwei/Dropbox/BCM/_Code/inversePOMDP/IRC_TwoSiteForaging/Results/01262020(151953)_data01262020(150900)_agentNN01262020(170602)_01262020IRC0_twoboxCol.pkl'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import IRC data (including trjectories and contour)\n",
    "\"\"\"\n",
    "dataN_pkl_file_IRC = open(path + '/Results/' + datestring_train + '_data' + datestring_data +  \n",
    "                   '_agentNN' + datestring_NNagent + '_' + datestring_IRC + 'IRC'+ str(idx) +'_twoboxCol' + '.pkl', 'rb')\n",
    "dataN_pkl_IRC = pickle.load(dataN_pkl_file_IRC)\n",
    "dataN_pkl_file_IRC.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN_pkl_IRC.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_final = dataN_pkl_IRC['point_final']\n",
    "point = dataN_pkl_IRC['point']\n",
    "point_add_gra = dataN_pkl_IRC['point_add_gra']\n",
    "point_all = dataN_pkl_IRC['point_all']\n",
    "uniques = dataN_pkl_IRC['uniques']\n",
    "#LL_slice = dataN_pkl_IRC['LL_slice']\n",
    "Loglikelihood = dataN_pkl_IRC['Loglikelihood']\n",
    "Qaux1 = dataN_pkl_IRC['Qaux1']\n",
    "Qaux2 = dataN_pkl_IRC['Qaux2']\n",
    "Qaux3 = dataN_pkl_IRC['Qaux3']\n",
    "Loglikelihood_original = dataN_pkl_IRC['Loglikelihood_original']\n",
    "uValue = dataN_pkl_IRC['uValue']\n",
    "uValuemesh = dataN_pkl_IRC['uValuemesh']\n",
    "vValue = dataN_pkl_IRC['vValue']\n",
    "vValuemesh = dataN_pkl_IRC['vValuemesh']\n",
    "projectionMat = dataN_pkl_IRC['projectionMat']\n",
    "belief1_est= dataN_pkl_IRC['belief1_est']\n",
    "belief2_est = dataN_pkl_IRC['belief2_est']\n",
    "belief1_est_MAP = dataN_pkl_IRC['belief1_est_MAP']\n",
    "belief2_est_MAP = dataN_pkl_IRC['belief2_est_MAP']\n",
    "belief1_est_EXP = dataN_pkl_IRC['belief1_est_EXP']\n",
    "belief2_est_EXP = dataN_pkl_IRC['belief2_est_EXP']\n",
    "quan_true_bel1 = dataN_pkl_IRC['quan_true_bel1_POMDP']\n",
    "quan_true_bel2 = dataN_pkl_IRC['quan_true_bel2_POMDP']\n",
    "hes_final = dataN_pkl_IRC['hes_final']\n",
    "std_final = dataN_pkl_IRC['std_para_woCol']\n",
    "var_para_woCol = dataN_pkl_IRC['var_para_woCol']\n",
    "LL_add_gra = dataN_pkl_IRC['LL_add_gra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import parameters of the NN agent in the test case\n",
    "\"\"\"\n",
    "\n",
    "para_pkl_file = open(path + '/Results/'+ datestring_train +'_data'+ datestring_data+\n",
    "                     '_agent' + datestring_NNagent + '_mainPara_twoboxCol.pkl', 'rb')\n",
    "para_pkl = pickle.load(para_pkl_file)\n",
    "para_pkl_file.close()\n",
    "nq, na, nr, nl, Numcol, discount, parametersAgent, parametersExp = para_pkl['NNtest_params']\n",
    "Numcol = parametersAgent[7]  # number of colors\n",
    "Ncol = Numcol - 1  # number value: 0 top Numcol-10.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import  of the NN agent in the test case, where the bahevior data is used by the IRC \n",
    "\"\"\"\n",
    "dataN_pkl_file1 = open(path + '/Results/'+ datestring_train + '_data' + datestring_data + \n",
    "                       '_agentNNdriven' + datestring_NNagent + '_twoboxCol.pkl', 'rb')\n",
    "dataN_pkl1 = pickle.load(dataN_pkl_file1)\n",
    "dataN_pkl_file1.close()\n",
    "\n",
    "T = dataN_pkl1['observations'].shape[1]\n",
    "obs = dataN_pkl1['observations'][idx,:T, :5].astype(int) \n",
    "lat = dataN_pkl1['POMDP_agent'][idx, :T, 1:]\n",
    "obs_IRC = dataN_pkl1['observations'][idx,:5000, :5].astype(int)   #NN agent behavior\n",
    "lat_IRC = dataN_pkl1['POMDP_agent'][idx, :5000, 1:]  #POMDP agent beliefs, for comparison\n",
    "\n",
    "act = obs[:, 0]\n",
    "rew = obs[:, 1]\n",
    "loc = obs[:, 2]\n",
    "col1 = obs[:, 3]\n",
    "col2 = obs[:, 4]\n",
    "\n",
    "act_POMDP = dataN_pkl1['POMDP_agent'][idx, :T, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## policy of the teacher POMDP and trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_policy_show = list(np.arange(35,66))\n",
    "fig_NNtraining, ax = plt.subplots(2,1,figsize=(8,4))\n",
    "\n",
    "ax[0].imshow(dataN_pkl1['POMDP_agent_dist'][idx,training_policy_show, :na].T, vmin = 0, vmax = 1)\n",
    "ax[0].set_ylabel('action',  fontsize = 20, color = 'green')\n",
    "ax[0].set_title ( 'target POMDP', fontsize = 20, color = 'green')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "\n",
    "im = ax[1].imshow(dataN_pkl1['observations'][idx, training_policy_show, -na:].T, vmin = 0, vmax = 1)\n",
    "ax[1].set_xlabel('time', fontsize = 16) \n",
    "ax[1].set_ylabel('action',  fontsize = 20, color = 'green')\n",
    "ax[1].set_title ( 'neural network', fontsize = 20, color = 'green')\n",
    "ax[1].set_xticks([0, 30])\n",
    "ax[1].set_yticks([])\n",
    "\n",
    "cbar_ax = fig_NNtraining.add_axes([0.93, 0.193, 0.015, 0.625])\n",
    "cb = plt.colorbar(im, cax=cbar_ax)\n",
    "for j, lab in enumerate(['0','1']):\n",
    "    cb.ax.text(2.4, j , lab, ha='center', va='center', fontsize = 16)\n",
    "cb.ax.get_yaxis().set_ticks([])\n",
    "cb.ax.get_yaxis().labelpad = 10\n",
    "cb.ax.set_ylabel('policy $\\pi(a_t|b_t)$', rotation=90, fontsize = 16, color = 'green')\n",
    "\n",
    "\n",
    "#plt.outline.set_visible(False)\n",
    "\n",
    "#fig_NNtraining.savefig('NNtraining.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour of IRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "figure for contour\n",
    "\"\"\"\n",
    "# project the trajectories onto the plane\n",
    "point_2d = projectionMat.dot((point_all - point_all[-1]).T).T   \n",
    "\n",
    "# true parameters projected onto the plane\n",
    "true_2d = projectionMat.dot(parametersAgent - point_all[-1])\n",
    "\n",
    "fig_contour, ax = plt.subplots(figsize = (8, 8))\n",
    "uValuemesh, vValuemesh = np.meshgrid(uValue[:], vValue[:])\n",
    "cs3 = plt.contourf(uValuemesh, vValuemesh, Loglikelihood[:, :], \n",
    "                  np.arange(np.min(Loglikelihood[:, :]), np.max(Loglikelihood[:, :]), 40), cmap='jet')\n",
    "plt.xticks(np.arange(-1, 1, 0.1), fontsize = 25)\n",
    "plt.yticks(np.arange(-1, 1, 0.1), fontsize = 25)\n",
    "\n",
    "plt.plot(point_2d[:, 0], point_2d[:, 1], marker='.', color = 'b', markersize = 14)   # projected trajectories\n",
    "plt.plot(point_2d[-1, 0], point_2d[-1, 1], marker='*', color = 'w', markersize = 16)        # final point\n",
    "plt.plot(true_2d[0], true_2d[1], marker='.', color = 'g', markersize = 14)           # true\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.set_title('Log likelihood of observed data', fontsize = 20, fontname = 'CMU Serif')\n",
    "plt.xlabel('\\n $\\mathbf{u} \\cdot \\mathbf{\\\\theta}$ \\n Projected parameters', fontsize = 40, fontname = 'CMU Serif')\n",
    "plt.ylabel('Projected parameters \\n $\\mathbf{v} \\cdot \\mathbf{\\\\theta}$', fontsize = 40, fontname = 'CMU Serif')\n",
    "#plt.clabel(cs3, inline=1, fontsize=10)\n",
    "cbar = plt.colorbar(cs3,fraction=0.046, pad=0.04)\n",
    "for j, lab in enumerate(['low','high']):\n",
    "    cbar.ax.text(2.4, j * 1100 - 6200, lab, ha='center', va='center', fontsize = 25)\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "cbar.ax.get_yaxis().labelpad = 10\n",
    "cbar.ax.set_ylabel('Log Likelihood', rotation=90, fontsize = 35, fontname = 'CMU Serif')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#fig_contour.savefig('contour.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_contour, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "prob_nor = np.exp(Loglikelihood - np.max(Loglikelihood))\n",
    "uValuemesh1, vValuemesh1 = np.meshgrid(uValue[:], vValue[:])\n",
    "cs_nor = plt.contour(uValuemesh1, vValuemesh1, prob_nor[:, :], \n",
    "                  np.arange(np.min(prob_nor[:,:]), np.max(prob_nor[:,:]), 0.1))\n",
    "\n",
    "plt.plot(point_2d[:, 0], point_2d[:, 1], marker='.', color = 'b')   # projected trajectories\n",
    "plt.plot(point_2d[-1, 0], point_2d[-1, 1], marker='*', color = 'w', markersize = 12)        # final point\n",
    "plt.plot(true_2d[0], true_2d[1], marker='o', color = 'r')           # true\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "#plt.xticks(np.arange(0, 1, 0.1))\n",
    "#plt.yticks(np.arange(0, 1, 0.1))\n",
    "ax.grid()\n",
    "ax.set_title('Contour of likelihood and trajectories')\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('v')\n",
    "plt.clabel(cs3, inline=1, fontsize=10)\n",
    "cbar = plt.colorbar(cs_nor,fraction=0.046, pad=0.04)\n",
    "for j, lab in enumerate(['low','high']):\n",
    "    cbar.ax.text(2.4, j , lab, ha='center', va='center', fontsize = 17, fontname = 'CMU Serif')\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "cbar.ax.get_yaxis().labelpad = 10\n",
    "cbar.ax.set_ylabel('Log Likelihood', rotation=90, fontsize = 18, fontname = 'CMU Serif')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para = np.copy(point_final)\n",
    "# para[-2] = 0.6\n",
    "# para[0] = 0.15\n",
    "# twoboxCol = twoboxColMDP(discount, nq, nr, na, nl, para)\n",
    "# twoboxCol.setupMDP()\n",
    "# if np.any(twoboxCol.ThA<0) == True:\n",
    "#     Qaux2[j, i] = np.nan\n",
    "#     Qaux3[j, i] = np.nan\n",
    "# else:\n",
    "#     twoboxCol.solveMDP_sfm()\n",
    "#     ThA = twoboxCol.ThA\n",
    "#     policy = twoboxCol.softpolicy\n",
    "#     pi = np.ones(nq * nq)/ nq /nq  # initialize the estimation of the belief state\n",
    "#     Trans_hybrid_obs12 = twoboxCol.Trans_hybrid_obs12\n",
    "#     Obs_emis_trans1 = twoboxCol.Obs_emis_trans1\n",
    "#     Obs_emis_trans2 = twoboxCol.Obs_emis_trans2\n",
    "#     twoboxColHMM = HMMtwoboxCol(ThA, policy, Trans_hybrid_obs12, Obs_emis_trans1, Obs_emis_trans2, pi, Ncol)\n",
    "\n",
    "#     #Qaux1[j, i] = twoboxHMM.likelihood(lat, obs, ThA, policy)  #given latent state\n",
    "# twoboxColHMM.computeQaux(obs_IRC, ThA, policy, Trans_hybrid_obs12, Obs_emis_trans1, Obs_emis_trans2) + twoboxColHMM.latent_entr(obs_IRC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparison of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparison of parameters\n",
    "\"\"\"\n",
    "\n",
    "N = 10\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.27       # the width of the bars\n",
    "\n",
    "fig_parameters = plt.figure(figsize = (12, 5))\n",
    "ax = fig_parameters.add_subplot(111)\n",
    "\n",
    "zvals = parametersAgent[:7] + parametersAgent[8:]\n",
    "yvals = point_final.tolist()[:7] + point_final.tolist()[8:]\n",
    "rects1 = ax.bar(ind, zvals, width, color='r')\n",
    "rects2 = ax.bar(ind+width, yvals, yerr=2*std_final, width = width, color = 'b', \n",
    "                align='center', alpha=1, ecolor='black', capsize=8)\n",
    "\n",
    "ax.set_title('Comparison of parameters', fontsize = 35)\n",
    "ax.set_ylabel('Parameters', fontsize = 30)\n",
    "ax.set_yticks([0, 0.5])\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20) \n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('Appearance \\n rate (box 1)', 'Appearance \\n rate (box 2)', 'Disappearance \\n rate (box 1)', \n",
    "                    'Disappearance \\n rate (box 2)','Grooming \\n reward', 'Traveling \\n cost', 'Pushing button \\n cost',\n",
    "                    'Color \\n parameter 1','Color \\n parameter 2', 'policy \\n temperature'), rotation=60, \n",
    "                   ha = 'center', fontsize = 20)\n",
    "leg = ax.legend( (rects1[0], rects2[0]), ('teacher\\'s parameters', 'estimated parameters' ), \n",
    "                fontsize = 20 , frameon=False)\n",
    "leg_c = ['r', 'b']\n",
    "for i, text in enumerate(leg.get_texts()):\n",
    "    plt.setp(text, color = leg_c[i])\n",
    "\n",
    "ax.xaxis.set_tick_params(length = 0)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "#fig_parameters.savefig('parameters.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('hes_final.csv', hes_final, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hes_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selec_idx = list(range(7)) + list(range(8,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, v = np.linalg.eig(hes_final[np.ix_(selec_idx, selec_idx)])\n",
    "w[5], v[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_final[selec_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[5]/np.sqrt(-w[5])/ point_final[selec_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_final / np.linalg.norm(std_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.abs(v[5]), std_final / np.linalg.norm(std_final))\n",
    "#plt.set_aspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sort = np.sort(w)\n",
    "w_sort / np.min(w_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eig = plt.figure(figsize = (10, 5))\n",
    "ax = fig_eig.add_subplot(111)\n",
    "\n",
    "plt.yscale('log')\n",
    "ax.bar(np.arange(N), -w_sort, color = 'blue')\n",
    "ax.set_xticks([])\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(18) \n",
    "\n",
    "\n",
    "plt.title('Absolute value of Hessian eigenvalues', fontsIZE = 20)\n",
    "#fig_eig.savefig('eigenSpectrum.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation/covariance between parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_correlation, ax = plt.subplots(figsize = (6, 6))\n",
    "correlation_mat = np.linalg.inv(np.diag(std_final)).dot(var_para_woCol).dot(np.linalg.inv(np.diag(std_final)))\n",
    "p_corre = ax.imshow(correlation_mat, \n",
    "                    cmap = 'bwr', vmax = np.max(np.abs(correlation_mat)), vmin = - np.max(np.abs(correlation_mat)))\n",
    "ax.set_title('Correlation of the parameters', fontsize = 26)\n",
    "ax.set_xticks(list(range(10)))\n",
    "ax.set_xticklabels( ('Appearance rate (box 1)', 'Appearance rate (box 2)', 'Disappearance rate (box 1)', \n",
    "                    'Disappearance rate (box 2)','Grooming reward', 'Traveling cost', 'Pushing button cost',\n",
    "                    'Color parameter 1','Color parameter 2', 'policy temperature'), rotation = 60, \n",
    "                   ha = 'right', fontsize = 18)\n",
    "ax.set_yticks(list(range(10)))\n",
    "ax.set_yticklabels( ('Appearance rate (box 1)', 'Appearance rate (box 2)', 'Disappearance rate (box 1)', \n",
    "                    'Disappearance rate (box 2)','Grooming reward', 'Traveling cost', 'Pushing button cost',\n",
    "                    'Color parameter 1','Color parameter 2', 'policy temperature'), ha = 'right', fontsize = 18)\n",
    "cbar = fig_correlation.colorbar(p_corre,fraction=0.046, pad=0.04)\n",
    "for j, lab in enumerate(['-1','0', '1']):\n",
    "    cbar.ax.text(2.4, j - 1, lab, ha='center', va='center', fontsize = 25)\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "cbar.ax.get_yaxis().labelpad = 10\n",
    "\n",
    "#fig_correlation.savefig('correlation.pdf', format='pdf', bbox_inches = 'tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cov, ax = plt.subplots(figsize = (6, 6))\n",
    "p_cov = ax.imshow(var_para_woCol, cmap = 'bwr', \n",
    "             vmin = -np.max(var_para_woCol), vmax = np.max(var_para_woCol))\n",
    "ax.set_title('Covariance of the parameters', fontsize = 26)\n",
    "ax.set_xticks(list(range(10)))\n",
    "ax.set_xticklabels( ('Appearance rate (box 1)', 'Appearance rate (box 2)', 'Disappearance rate (box 1)', \n",
    "                    'Disappearance rate (box 2)','Grooming reward', 'Traveling cost', 'Pushing button cost',\n",
    "                    'Color parameter 1','Color parameter 2', 'policy temperature'), rotation = 60, \n",
    "                   ha = 'right', fontsize = 18)\n",
    "ax.set_yticks(list(range(10)))\n",
    "ax.set_yticklabels( ('Appearance rate (box 1)', 'Appearance rate (box 2)', 'Disappearance rate (box 1)', \n",
    "                    'Disappearance rate (box 2)','Grooming reward', 'Traveling cost', 'Pushing button cost',\n",
    "                    'Color parameter 1','Color parameter 2', 'policy temperature'), ha = 'right', fontsize = 18)\n",
    "\n",
    "cbar = fig_cov.colorbar(p_cov,fraction=0.046, pad=0.04)\n",
    "\n",
    "for j, lab in enumerate(['low','0', 'high']):\n",
    "    cbar.ax.text(0.008, 0.0015 * (j - 1), lab, ha='center', va='center', fontsize = 25)\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "cbar.ax.get_yaxis().labelpad = 10\n",
    "\n",
    "#fig_cov.savefig('covariance.pdf', format='pdf', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# posterior based on estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_array = (np.arange(nq) + 1/2)/nq\n",
    "belief_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# beliefs of the POMDP agent\n",
    "# \"\"\"\n",
    "# # quan_true_bel1 = find_closest_array(belief_array, lat[:, 0])\n",
    "# # quan_true_bel2 = find_closest_array(belief_array, lat[:, 1])\n",
    "# quan_true_bel1 = (lat[:, 0] + 1/2)/nq\n",
    "# quan_true_bel2 = (lat[:, 1] + 1/2)/nq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_est = np.copy(point_final)\n",
    "twoboxCol_est = twoboxColMDP(discount, nq, nr, na, nl, para_est)\n",
    "twoboxCol_est.setupMDP()\n",
    "twoboxCol_est.solveMDP_sfm()\n",
    "ThA = twoboxCol_est.ThA\n",
    "policy = twoboxCol_est.softpolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi = np.ones(nq * nq)/ nq /nq  # initialize the estimation of the belief state\n",
    "# Trans_hybrid_obs12 = twoboxCol_est.Trans_hybrid_obs12\n",
    "# Obs_emis_trans1 = twoboxCol_est.Obs_emis_trans1\n",
    "# Obs_emis_trans2 = twoboxCol_est.Obs_emis_trans2\n",
    "# twoboxColHMM_est = HMMtwoboxCol(ThA, policy, Trans_hybrid_obs12, Obs_emis_trans1, Obs_emis_trans2, pi, Ncol)\n",
    "\n",
    "# twoboxColHMM_est.computeQaux(obs, ThA, policy, Trans_hybrid_obs12, Obs_emis_trans1, Obs_emis_trans2)+ \\\n",
    "# twoboxColHMM_est.latent_entr(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_est, scale_est = twoboxColHMM_est.forward_scale(obs)\n",
    "# beta_est = twoboxColHMM_est.backward_scale(obs, scale_est)\n",
    "# gamma_est = twoboxColHMM_est.compute_gamma(alpha_est, beta_est)\n",
    "# xi_est = twoboxColHMM_est.compute_xi(alpha_est, beta_est, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# belief1_est = np.sum(np.reshape(gamma_est[:, :].T, (gamma_est.shape[-1], nq, nq)), axis = 2)\n",
    "# belief2_est = np.sum(np.reshape(gamma_est[:, :].T,(gamma_est.shape[-1], nq, nq)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# belief1_est_MAP = (np.argmax(belief1_est, axis = 1) + 0.5)/nq\n",
    "# belief2_est_MAP = (np.argmax(belief2_est, axis = 1) + 0.5)/nq\n",
    "\n",
    "# belief1_est_EXP = belief1_est.dot(belief_array)\n",
    "# belief2_est_EXP = belief2_est.dot(belief_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_posterior = plt.figure(figsize= (15, 10))\n",
    "showlen = 100\n",
    "startT = 440 \n",
    "\n",
    "endT = startT + showlen\n",
    "showT = range(startT,endT)\n",
    "\n",
    "fig_posterior, [ax3, ax1, ax_loc, ax4, ax2] = plt.subplots(5, 1, figsize= (15, 10))\n",
    "#plt.figure(figsize = (15,10))\n",
    "#gs1 = gridspec.GridSpec(5, 1, height_ratios=[3, 3, 3, 1, 3])\n",
    "#gs1.update(wspace=0.025, hspace=0) # set the spacing between axes. \n",
    "\n",
    "#ax3 = plt.subplot(gs1[0])\n",
    "#ax3 = fig_posterior.add_subplot(511)\n",
    "ax3.imshow(np.tile(col1[showT], (3,1)), cmap = cmap_col5,vmin=0, vmax=Ncol)\n",
    "ax3.yaxis.set_label_coords(-0.1,0)\n",
    "ax3.set_ylabel('box 1 color', color = 'slateblue', rotation= 360, fontsize = 22)\n",
    "#ax3.xaxis.set_tick_params(length = 0)\n",
    "#ax3.set_xlim([0, showlen])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['bottom'].set_visible(False)\n",
    "ax3.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "#ax1 = plt.subplot(gs1[1])\n",
    "#ax1 = fig_posterior.add_subplot(512)\n",
    "ax1.imshow(belief1_est[showT].T, interpolation='Nearest', cmap='gray', origin='lower', aspect='auto')\n",
    "ax1.plot(lat[showT, 0], color = 'dodgerblue', markersize = 10,linewidth=3.0)\n",
    "#ax1.set(title = 'belief of box 1 based on estimated parameters')\n",
    "#ax1.get_yaxis().labelpad = 70\n",
    "ax1.yaxis.set_label_coords(-0.1,0.25)\n",
    "ax1.set_ylabel('Marginal belief \\n about box 1', rotation= 360, fontsize = 22)\n",
    "#ax1.set_xlim([0, showlen])\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([0, nq-1])\n",
    "ax1.set_yticklabels(['0','1'])\n",
    "ax1.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "\n",
    "\n",
    "#ax_loc = plt.subplot(gs1[2])\n",
    "#ax_loc = fig_posterior.add_subplot(513)\n",
    "ax_loc.plot((np.remainder(loc[showT]+1, 3) - 1 ) * 10, 'g.-', markersize = 12, linewidth = 5)\n",
    "#ax_loc.plot((np.remainder(loc[showT]+1, 3) - 1 ) * 10, 'm-')\n",
    "# ax_loc.plot(act[showT] // 4 * 10 * (np.abs(loc[showT]* 2 - 1.5) - 0.5 - 1), \n",
    "#              'v', markersize = 5)\n",
    "# ax_loc.plot(rew[showT] * 9, 'c*')\n",
    "box1_r = act[showT] // 4 * 7 * np.remainder(loc[showT]+1, 3) * np.insert(rew[showT][1:], -1, 0) * 1.0 \n",
    "box2_r = act[showT] // 4 * 7 * (np.remainder(loc[showT]+1, 3) - 2) * np.insert(rew[showT][1:], -1, 0) * 1.0\n",
    "box1_n = act[showT] // 4 * 7 * np.remainder(loc[showT]+1, 3) * (1-np.insert(rew[showT][1:], -1, 0))* 1.0 * (loc[showT] != 0)\n",
    "box2_n = act[showT] // 4 * 7 * ((np.remainder(loc[showT]+1, 3) - 2) * (1-np.insert(rew[showT][1:], -1, 0)))* 1.0 * (loc[showT] != 0)\n",
    "box1_r[ box1_r==0 ] = np.nan\n",
    "box2_n[ box2_n==0 ] = np.nan\n",
    "box2_r[ box2_r==0 ] = np.nan\n",
    "box1_n[ box1_n==0 ] = np.nan\n",
    "ax_loc.plot(box2_r, '^', c = 'red', markersize = 15)\n",
    "ax_loc.plot(box1_n, 'v', c = 'blue', markersize = 15)\n",
    "ax_loc.plot(box2_n, '^', c = 'blue', markersize = 15)\n",
    "ax_loc.plot(box1_r, 'v', c = 'red', markersize = 15)\n",
    "\n",
    "ax_loc.set_xlim([0,showlen])\n",
    "ax_loc.spines['top'].set_visible(False)\n",
    "ax_loc.spines['right'].set_visible(False)\n",
    "ax_loc.spines['bottom'].set_visible(False)\n",
    "ax_loc.spines['left'].set_visible(False)\n",
    "#ax_loc.set_ylim([1,16])\n",
    "ax_loc.set_yticks([])\n",
    "ax_loc.set_xticks([])\n",
    "\n",
    "\n",
    "\n",
    "#ax2 = plt.subplot(gs1[4])\n",
    "#ax2 = fig_posterior.add_subplot(515)\n",
    "ax2.imshow(belief2_est[showT].T, interpolation='Nearest', cmap='gray', origin='lower',aspect='auto')\n",
    "ax2.plot(lat[showT, 1], color = 'dodgerblue', markersize = 10,linewidth=3.0)\n",
    "#ax2.set(title = 'belief of box 2 based on estimated parameters')\n",
    "ax2.set_xlabel('time', fontsize = 18)\n",
    "#ax2.get_yaxis().labelpad = 70\n",
    "ax2.yaxis.set_label_coords(-0.1,0.25)\n",
    "ax2.set_ylabel('Marginal belief \\n about box 2', rotation= 360, fontsize = 22)\n",
    "#ax2.set_xticks([])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax2.set_yticks([0, nq-1])\n",
    "ax2.set_yticklabels(['0','1'])\n",
    "\n",
    "\n",
    "#ax4 = plt.subplot(gs1[3])\n",
    "#ax4 = fig_posterior.add_subplot(514)\n",
    "ax4.imshow(np.tile(col2[showT], (3,1)), cmap = cmap_col5,vmin=0, vmax=Ncol)\n",
    "#ax4.get_yaxis().labelpad = 70\n",
    "ax4.yaxis.set_label_coords(-0.1,0)\n",
    "ax4.set_ylabel('box 2 color', color = 'slateblue', rotation= 360, fontsize = 22)\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax4.spines['right'].set_visible(False)\n",
    "ax4.spines['bottom'].set_visible(False)\n",
    "ax4.spines['left'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#fig_posterior.savefig('posterior.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual1 = np.zeros((nq,nq))\n",
    "for i in range(nq):\n",
    "    index = np.where(lat[:, 0]==i)\n",
    "    #mutual1[i] = np.sum(belief1_allest.T[:, index[0].tolist()], axis = 1)/np.size(index)\n",
    "    mutual1[:, i] = np.sum(belief1_est.T[:, index[0].tolist()], axis = 1) /np.size(index)\n",
    "    mutual1[:, i] = mutual1[:, i] / np.sum(mutual1[:, i] )\n",
    "\n",
    "mutual2 = np.zeros((nq,nq))\n",
    "for i in range(nq):\n",
    "    index = np.where(lat[:, 1]==i)\n",
    "    mutual2[:, i] = np.sum(belief2_est.T[:, index[0].tolist()], axis = 1) /np.size(index)\n",
    "    mutual2[:, i] = mutual2[:, i] / np.sum(mutual2[:, i] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_beliefdist, ax = plt.subplots(2, 1, figsize=(6,8), sharex=True)\n",
    "fig_beliefdist.text(0.1, 0, 'Average distribution of belief posterior',\n",
    "                    fontsize = 30, rotation = 90)\n",
    "\n",
    "ax[0].imshow(mutual1, origin='lower', extent=[0,1,0,1], vmin=0, vmax=1)\n",
    "ax[0].xaxis.set_major_formatter(FormatStrFormatter('%.0f'))        \n",
    "ax[0].yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "#ax[0].set_xticks([0, 1])\n",
    "ax[0].set_yticks([0, 1])\n",
    "ax[0].text(.1, .8, 'box1',  color = 'white', fontsize = 20.0,\n",
    "        bbox={'facecolor': 'none', 'alpha': 0, 'pad': 8})\n",
    "\n",
    "im = ax[1].imshow(mutual2, origin='lower', extent=[0,1,0,1], vmin=0, vmax=1)\n",
    "ax[1].xaxis.set_major_formatter(FormatStrFormatter('%.0f'))        \n",
    "ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "ax[1].set_xticks([0, 1])\n",
    "ax[1].set_yticks([0, 1])\n",
    "ax[1].text(.1, .8, 'box2',  color = 'white', fontsize = 20.0,\n",
    "        bbox={'facecolor': 'none', 'alpha': 0, 'pad': 8})\n",
    "\n",
    "\n",
    "\n",
    "cbar = fig_beliefdist.colorbar(im, ax=ax.ravel().tolist(), shrink=1, aspect=30)\n",
    "for j, lab in enumerate(['0','1']):\n",
    "    cbar.ax.text(2.4, j , lab, ha='center', va='center', fontsize = 17, fontname = 'CMU Serif')\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "cbar.ax.get_yaxis().labelpad = 10\n",
    "cbar.ax.set_ylabel('Frequency of co-occurence', rotation=90, fontsize = 30, fontname = 'CMU Serif')\n",
    "\n",
    "\n",
    "#fig_beliefdist.savefig('belief_conditionaldist.pdf', format='pdf', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Neural coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from pandas import DataFrame, read_csv\n",
    "\n",
    "\n",
    "# bbelief = np.dstack([dataN_pkl_IRC['belief1_est_MAP'], dataN_pkl_IRC['belief2_est_MAP']])\n",
    "# bb = bbelief.reshape(-1, 2)\n",
    "\n",
    "# bb_df = DataFrame(bb, columns=['behavior_belief1', 'behavior_belief2'])\n",
    "# bb_df.to_csv(path_or_buf='./data/bb_df.csv', index=False)\n",
    "\n",
    "# r = dataN_pkl1['neural_response'][idx, :T, :]\n",
    "# r_df = DataFrame(r)  # no colurmn name\n",
    "# r_df.to_csv(path_or_buf='./data/r_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!python data_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from data_preprocessing_notebook import *\n",
    "# data_preprocessing_notebook(idx,datestring_train,\n",
    "#                             datestring_data,\n",
    "#                             datestring_NNagent, \n",
    "#                             POMDP = False, ENCODING = True, DECODING = True, RECODING = True, NEURAL_NUM = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# check std of beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bel1_std = np.sum(np.multiply(np.square(np.tile(belief_array, (T,1)).T - np.tile(belief1_est_EXP, (nq,1))), \n",
    "#                    belief1_est.T), axis = 0)\n",
    "# plt.scatter(quan_true_bel1, bel1_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# para_check_set = rmv_dup_arrary(point)\n",
    "# bel_std_set = np.zeros((2,len(para_check_set), T))\n",
    "# bel_MAP_set = np.zeros((2,len(para_check_set), T))\n",
    "\n",
    "# for i, para_test in enumerate(para_check_set):\n",
    "#     para_test = np.copy(para_test)\n",
    "#     twoboxCol_test = twoboxColMDP(discount, nq, nr, na, nl, para_test)\n",
    "#     twoboxCol_test.setupMDP()\n",
    "#     twoboxCol_test.solveMDP_sfm()\n",
    "#     ThA = twoboxCol_test.ThA\n",
    "#     policy = twoboxCol_test.softpolicy\n",
    "#     pi = np.ones(nq * nq)/ nq /nq  # initialize the estimation of the belief state\n",
    "#     Trans_hybrid_obs12 = twoboxCol_test.Trans_hybrid_obs12\n",
    "#     Obs_emis_trans1 = twoboxCol_test.Obs_emis_trans1\n",
    "#     Obs_emis_trans2 = twoboxCol_test.Obs_emis_trans2\n",
    "#     twoboxColHMM_test = HMMtwoboxCol(ThA, policy, Trans_hybrid_obs12, Obs_emis_trans1, Obs_emis_trans2, pi, Ncol)\n",
    "    \n",
    "#     alpha_test, scale_test = twoboxColHMM_test.forward_scale(obs)\n",
    "#     beta_test = twoboxColHMM_test.backward_scale(obs, scale_test)\n",
    "#     gamma_test = twoboxColHMM_test.compute_gamma(alpha_test, beta_test)\n",
    "#     xi_test = twoboxColHMM_test.compute_xi(alpha_test, beta_test, obs)\n",
    "    \n",
    "#     belief1_test = np.sum(np.reshape(gamma_test[:, :].T, (T, nq, nq)), axis = 2)\n",
    "#     belief2_test = np.sum(np.reshape(gamma_test[:, :].T, (T, nq, nq)), axis = 1)\n",
    "#     #print(belief1_test[:10, 0])\n",
    "    \n",
    "#     belief1_test_EXP = belief1_test.dot(belief_array)\n",
    "#     belief2_test_EXP = belief2_test.dot(belief_array)\n",
    "    \n",
    "#     bel_MAP_set[0,i,:] = (np.argmax(belief1_test, axis = 1) + 0.5)/nq\n",
    "#     bel_MAP_set[1,i,:] = (np.argmax(belief2_test, axis = 1) + 0.5)/nq\n",
    "\n",
    "\n",
    "    \n",
    "#     bel_std_set[0, i, :] = np.sum(np.multiply(np.square(np.tile(belief_array, (T,1)).T - np.tile(belief1_test_EXP, (nq,1))), \n",
    "#                    belief1_test.T), axis = 0)\n",
    "#     bel_std_set[1, i, :] = np.sum(np.multiply(np.square(np.tile(belief_array, (T,1)).T - np.tile(belief1_test_EXP, (nq,1))), \n",
    "#                    belief1_test.T), axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5.15, 5.15))\n",
    "# plt.clf()\n",
    "# plt.subplot(111)\n",
    "# for i in range(len(uniques)):\n",
    "#     plt.scatter(quan_true_bel1, bel_std_set[0, 1])\n",
    "# plt.xlabel('POMDP belief')\n",
    "# plt.ylabel('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5.15, 5.15))\n",
    "# plt.clf()\n",
    "# plt.subplot(111)\n",
    "# for i in range(len(uniques)):\n",
    "#     plt.scatter(bel_MAP_set[0,i], bel_std_set[0, i])\n",
    "# plt.xlabel('MAP belief')\n",
    "# plt.ylabel('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Calculate Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# L =len(parametersAgent)\n",
    "# hes = np.zeros((L,L))\n",
    "\n",
    "# paraHessian = point[-1]\n",
    "# twoboxd = twoboxColMDP_der(discount, nq, nr, na, nl, paraHessian)\n",
    "# twoboxd1st = twoboxd.dloglikelihhod_dpara_sim(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# perturb = 10** -6\n",
    "# for i in range(L):\n",
    "#     if i != 7:\n",
    "#         para_perb = np.copy(paraHessian)\n",
    "#         para_perb[i] += perturb\n",
    "\n",
    "#         twoboxd_perb = twoboxColMDP_der(discount, nq, nr, na, nl, para_perb)       \n",
    "#         twoboxd1st_pert = twoboxd_perb.dloglikelihhod_dpara_sim(obs)\n",
    "\n",
    "#         hes[i, :] = (twoboxd1st_pert - twoboxd1st) / perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# w, v = np.linalg.eig(hes)\n",
    "# w, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# behavioral statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from POMDP_generate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsN_est, latN_est, truthN_est, _ = twoboxColGenerate(point_final, \n",
    "                                                      parametersExp, sample_length = T, sample_number = 1, nq = 5, \n",
    "                                                      save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_est = obsN_est[0]\n",
    "lat_est = latN_est[0]\n",
    "\n",
    "act_est = obs_est[:, 0]\n",
    "rew_est = obs_est[:, 1]\n",
    "loc_est = obs_est[:, 2]\n",
    "col1_est = obs_est[:, 3]\n",
    "col2_est = obs_est[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of actions\n",
    "fig1, ax = plt.subplots()\n",
    "plt.title('distribution of actions', fontsize = 16)\n",
    "plt.hist([np.squeeze(act), np.squeeze(act_est)], bins = [0,1,2,3,4,5], \n",
    "         color = ['red','blue'], label = ['true', 'estimated'], alpha = 0.8)\n",
    "plt.legend()\n",
    "#ax[1].hist(np.squeeze(action), bins = 5, normed=False, weights=weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of locations\n",
    "fig2, ax = plt.subplots()\n",
    "plt.title('distribution of locations', fontsize = 16)\n",
    "plt.hist([np.squeeze(loc), np.squeeze(loc_est)], \n",
    "         bins = 5, color = ['red','blue'], label = ['true', 'estimated'], alpha = 0.8)\n",
    "plt.legend()\n",
    "#ax[1].hist(np.squeeze(action), bins = 5, normed=False, weights=weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbind_est = np.where(np.squeeze(act_est) == 4)[0]\n",
    "pbind = np.where(np.squeeze(act) == 4)[0]\n",
    "pbind_POMDP = np.where(np.squeeze(act_POMDP) == 4)[0]\n",
    "\n",
    "# time between two pb\n",
    "fig3, ax = plt.subplots()\n",
    "plt.title('time between two pb', fontsize = 16)\n",
    "plt.hist([pbind[1:] - pbind[0:-1], pbind_est[1:] - pbind_est[0:-1]],\n",
    "        bins = np.linspace(0, 40, 10), alpha = 0.8, color = ['red','blue'], label = ['true', 'estimated'])\n",
    "plt.legend()\n",
    "#ax[1].hist(pbind[1:] - pbind[0:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travelind_est = np.concatenate((np.where(np.squeeze(act_est) == 1)[0], \n",
    "                              np.where(np.squeeze(act_est) == 2)[0],\n",
    "                              np.where(np.squeeze(act_est) == 3)[0]))\n",
    "travelind = np.concatenate((np.where(np.squeeze(act) == 1)[0], \n",
    "                              np.where(np.squeeze(act) == 2)[0],\n",
    "                              np.where(np.squeeze(act) == 3)[0]))\n",
    "travelind_POMDP = np.concatenate((np.where(np.squeeze(act_POMDP) == 1)[0], \n",
    "                              np.where(np.squeeze(act_POMDP) == 2)[0],\n",
    "                              np.where(np.squeeze(act_POMDP) == 3)[0]))\n",
    "\n",
    "\n",
    "\n",
    "# time between two travelling\n",
    "fig4, ax = plt.subplots()\n",
    "plt.title('time between travelling', fontsize = 16)\n",
    "plt.hist([travelind[1:] - travelind[0:-1], travelind_est[1:] - travelind_est[0:-1]], \n",
    "         bins = np.linspace(0, 40, 10), \n",
    "         color = ['red','blue'], label = ['true', 'estimated'], alpha = 0.8)\n",
    "plt.legend()\n",
    "#ax[1].hist(pbind[1:] - pbind[0:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "behavioral statistics of an agent with IRC parameter\n",
    "histogram NOT normalized\n",
    "\"\"\"\n",
    "fig_behav, ax = plt.subplots(2, 2, figsize=(10, 9))\n",
    "\n",
    "ax[0, 0].hist([np.squeeze(act_POMDP), np.squeeze(act), np.squeeze(act_est)], bins = [0,1,2,3,4,5], \n",
    "         color = ['green', 'red','blue'], label = ['POMDP','NN', 'IRCagent'], alpha = 0.8)\n",
    "ax[0, 0].legend(fontsize = 12, frameon = False)\n",
    "ax[0, 0].set_title('Actions', fontsize = 30)\n",
    "labels = [item.get_text() for item in ax[0, 0].get_xticklabels()]\n",
    "labels[1] = 'do \\n nothing'\n",
    "labels[2] = 'go to \\n center'\n",
    "labels[3] = 'go to 1'\n",
    "labels[4] = 'go to 2'\n",
    "labels[5] = 'push \\n button'\n",
    "ax[0, 0].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[0, 0].set_xticklabels(labels, rotation=60, ha = 'center', fontsize = 20)\n",
    "ax[0, 0].xaxis.set_tick_params(length = 0)\n",
    "ax[0, 0].set_yticks([])\n",
    "ax[0, 0].spines['top'].set_visible(False)\n",
    "ax[0, 0].spines['right'].set_visible(False)\n",
    "ax[0, 0].spines['bottom'].set_visible(False)\n",
    "ax[0, 0].spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax[0, 1].set_title('Locations', fontsize = 30)\n",
    "ax[0, 1].hist([np.squeeze(loc), np.squeeze(loc), np.squeeze(loc_est)], \n",
    "         bins = 5, color = ['green', 'red','blue'], label = ['POMDP', 'NN', 'IRCagent'], alpha = 0.8)\n",
    "ax[0, 1].set_xticks(np.arange(0, 2, 0.2))\n",
    "labels = [item.get_text() for item in ax[0, 1].get_xticklabels()]\n",
    "labels[1] = 'center'\n",
    "labels[5] = 'box 1'\n",
    "labels[9] = 'box 2'\n",
    "ax[0, 1].set_xticklabels(labels, ha = 'center', fontsize = 20)\n",
    "ax[0, 1].xaxis.set_tick_params(length = 0)\n",
    "ax[0, 1].set_yticks([])\n",
    "ax[0, 1].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[0, 1].spines['top'].set_visible(False)\n",
    "ax[0, 1].spines['right'].set_visible(False)\n",
    "ax[0, 1].spines['bottom'].set_visible(False)\n",
    "ax[0, 1].spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax[1, 0].set_title('Time between \\n button pushes', fontsize = 30)\n",
    "ax[1, 0].hist([pbind_POMDP[1:] - pbind_POMDP[0:-1], \n",
    "               pbind[1:] - pbind[0:-1], \n",
    "               pbind_est[1:] - pbind_est[0:-1]],\n",
    "        bins = np.linspace(0, 40, 8), alpha = 0.8, \n",
    "              color = ['green', 'red','blue'], label = ['POMDP', 'NN', 'IRCagent'])\n",
    "ax[1, 0].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[1, 0].set_xticks(range(0,41, 3))\n",
    "labels = [item.get_text() for item in ax[1, 0].get_xticklabels()]\n",
    "labels[1] = '0-5'\n",
    "labels[6] = '15-20 \\n time'\n",
    "labels[11] = '35-40'\n",
    "ax[1, 0].set_xticklabels(labels, ha = 'center', fontsize = 20)\n",
    "ax[1, 0].xaxis.set_tick_params(length = 0)\n",
    "ax[1, 0].set_yticks([])\n",
    "ax[1, 0].spines['top'].set_visible(False)\n",
    "ax[1, 0].spines['right'].set_visible(False)\n",
    "ax[1, 0].spines['bottom'].set_visible(False)\n",
    "ax[1, 0].spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax[1, 1].set_title('Time between \\n travel', fontsize = 30)\n",
    "ax[1, 1].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[1, 1].hist([travelind_POMDP[1:] - travelind_POMDP[0:-1], \n",
    "               travelind[1:] - travelind[0:-1], \n",
    "               travelind_est[1:] - travelind_est[0:-1]], \n",
    "         bins = np.linspace(0, 40, 8), \n",
    "         color = ['green', 'red','blue'], label = ['POMDP', 'NN', 'IRCagent'], alpha = 0.8)\n",
    "ax[1, 1].set_xticks(range(0,41, 3))\n",
    "labels = [item.get_text() for item in ax[1, 1].get_xticklabels()]\n",
    "labels[1] = '0-5'\n",
    "labels[6] = '15-20 \\n time'\n",
    "labels[11] = '35-40'\n",
    "ax[1, 1].set_xticklabels(labels, ha = 'center', fontsize = 20)\n",
    "ax[1, 1].xaxis.set_tick_params(length = 0)\n",
    "ax[1, 1].set_yticks([])\n",
    "ax[1, 1].spines['top'].set_visible(False)\n",
    "ax[1, 1].spines['right'].set_visible(False)\n",
    "ax[1, 1].spines['bottom'].set_visible(False)\n",
    "ax[1, 1].spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig_behav.savefig('behavior_state.pdf', format='pdf', bbox_inches = 'tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "behavioral statistics of an agent with IRC parameter\n",
    "histogram NORMALIZED\n",
    "\"\"\"\n",
    "\n",
    "fig_behav, ax = plt.subplots(2, 2, figsize=(10, 9))\n",
    "\n",
    "weights_act_POMDP = np.ones_like(np.squeeze(act_POMDP))/float(len(np.squeeze(act_POMDP)))\n",
    "weights_act = np.ones_like(np.squeeze(act))/float(len(np.squeeze(act)))\n",
    "weights_act_IRC = np.ones_like(np.squeeze(act_est))/float(len(np.squeeze(act_est)))\n",
    "\n",
    "\n",
    "heights, bins, batch = ax[0, 0].hist([np.squeeze(act_POMDP), np.squeeze(act), np.squeeze(act_est)], \n",
    "              weights = [weights_act_POMDP, weights_act, weights_act_IRC], bins = [0,1,2,3,4,5], \n",
    "         color = ['green', 'red','blue'], label = ['POMDP','NN', 'IRCagent'])\n",
    "print(np.sum(heights[0]), np.sum(heights[0]), np.sum(heights[0]))\n",
    "ax[0, 0].legend(fontsize = 12, frameon = False)\n",
    "ax[0, 0].set_title('Actions', fontsize = 30)\n",
    "labels = [item.get_text() for item in ax[0, 0].get_xticklabels()]\n",
    "labels[1] = 'do \\n nothing'\n",
    "labels[2] = 'go to \\n center'\n",
    "labels[3] = 'go to 1'\n",
    "labels[4] = 'go to 2'\n",
    "labels[5] = 'push \\n button'\n",
    "ax[0, 0].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[0, 0].set_xticklabels(labels, rotation=60, ha = 'center', fontsize = 20)\n",
    "ax[0, 0].xaxis.set_tick_params(length = 0)\n",
    "ax[0, 0].spines['top'].set_visible(False)\n",
    "ax[0, 0].spines['right'].set_visible(False)\n",
    "ax[0, 0].spines['bottom'].set_visible(False)\n",
    "ax[0, 0].spines['left'].set_visible(False)\n",
    "ax[0, 0].set_yticks([0, .8])\n",
    "\n",
    "weights_loc = np.ones_like(np.squeeze(loc))/float(len(np.squeeze(loc)))\n",
    "weights_loc_IRC = np.ones_like(np.squeeze(loc_est))/float(len(np.squeeze(loc_est)))\n",
    "\n",
    "ax[0, 1].set_title('Locations', fontsize = 30)\n",
    "heights, bins, batch = ax[0, 1].hist([np.squeeze(np.abs(2*loc - 3/2)-1/2), \n",
    "                                      np.squeeze(np.abs(2*loc - 3/2)-1/2), \n",
    "                                      np.squeeze(np.abs(2*loc_est - 3/2)-1/2)],\n",
    "                                     weights = [weights_loc, weights_loc, weights_loc_IRC],\n",
    "         bins = 5, color = ['green', 'red','blue'], label = ['POMDP', 'NN', 'IRCagent'])\n",
    "print(np.sum(heights[0]), np.sum(heights[0]), np.sum(heights[0]))\n",
    "ax[0, 1].set_xticks(np.arange(0, 2, 0.2))\n",
    "labels = [item.get_text() for item in ax[0, 1].get_xticklabels()]\n",
    "labels[1] = 'center'\n",
    "labels[5] = 'box 1'\n",
    "labels[9] = 'box 2'\n",
    "ax[0, 1].set_xticklabels(labels, ha = 'center', fontsize = 20)\n",
    "ax[0, 1].xaxis.set_tick_params(length = 0)\n",
    "ax[0, 1].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[0, 1].spines['top'].set_visible(False)\n",
    "ax[0, 1].spines['right'].set_visible(False)\n",
    "ax[0, 1].spines['bottom'].set_visible(False)\n",
    "ax[0, 1].spines['left'].set_visible(False)\n",
    "ax[0, 1].set_yticks([0, .8])\n",
    "\n",
    "\n",
    "weights_pbind_POMDP = np.ones_like(pbind_POMDP[1:] )/float(len(pbind_POMDP[1:] ))\n",
    "weights_pbind = np.ones_like(pbind[1:])/float(len(pbind[1:] ))\n",
    "weights_pbind_IRC = np.ones_like(pbind_est[1:])/float(len(pbind_est[1:]))\n",
    "\n",
    "ax[1, 0].set_title('Time between \\n button pushes', fontsize = 30)\n",
    "heights, bins, batch = ax[1, 0].hist([pbind_POMDP[1:] - pbind_POMDP[0:-1], \n",
    "               pbind[1:] - pbind[0:-1], \n",
    "               pbind_est[1:] - pbind_est[0:-1]],\n",
    "              weights = [weights_pbind_POMDP, weights_pbind, weights_pbind_IRC],\n",
    "              bins = np.linspace(0, 40, 8),  \n",
    "              color = ['green', 'red','blue'], label = ['POMDP', 'NN', 'IRCagent'])\n",
    "print(heights)\n",
    "print(np.sum(heights[0]), np.sum(heights[0]), np.sum(heights[0]))\n",
    "ax[1, 0].set_ylabel('Frequency', fontsize = 20)\n",
    "ax[1, 0].set_xticks(range(0,41, 3))\n",
    "labels = [item.get_text() for item in ax[1, 0].get_xticklabels()]\n",
    "labels[1] = '0-5'\n",
    "labels[6] = '15-20 \\n time'\n",
    "labels[11] = '35-40'\n",
    "ax[1, 0].set_xticklabels(labels, ha = 'center', fontsize = 20)\n",
    "ax[1, 0].xaxis.set_tick_params(length = 0)\n",
    "ax[1, 0].set_yticks([])\n",
    "ax[1, 0].spines['top'].set_visible(False)\n",
    "ax[1, 0].spines['right'].set_visible(False)\n",
    "ax[1, 0].spines['bottom'].set_visible(False)\n",
    "ax[1, 0].spines['left'].set_visible(False)\n",
    "ax[1, 0].set_yticks([0, .8])\n",
    "\n",
    "#\n",
    "weights_travelind_POMDP = np.ones_like(travelind_POMDP[1:] )/float(len(travelind_POMDP[1:] ))\n",
    "weights_travelind = np.ones_like(travelind[1:])/float(len(travelind[1:] ))\n",
    "weights_travelind_IRC = np.ones_like(travelind_est[1:])/float(len(travelind_est[1:]))\n",
    "\n",
    "ax[1, 1].set_title('Time between \\n travel', fontsize = 30)\n",
    "ax[1, 1].set_ylabel('Frequency', fontsize = 20)\n",
    "heights, xbins, ptchs = ax[1, 1].hist([travelind_POMDP[1:] - travelind_POMDP[0:-1], \n",
    "               travelind[1:] - travelind[0:-1], \n",
    "               travelind_est[1:] - travelind_est[0:-1]], \n",
    "              weights = [weights_travelind_POMDP, weights_travelind, weights_travelind_IRC], \n",
    "              bins = np.linspace(0, 40, 8), \n",
    "              color = ['green', 'red','blue'], label = ['POMDP', 'NN', 'IRCagent'])\n",
    "print(heights)\n",
    "print(np.sum(heights[0]), np.sum(heights[0]), np.sum(heights[0]))\n",
    "\n",
    "ax[1, 1].set_xticks(range(0,41, 3))\n",
    "labels = [item.get_text() for item in ax[1, 0].get_xticklabels()]\n",
    "labels[1] = '0-5'\n",
    "labels[6] = '15-20 \\n time'\n",
    "labels[11] = '35-40'\n",
    "\n",
    "\n",
    "ax[1, 1].set_xticklabels(labels, ha = 'center', fontsize = 20)\n",
    "ax[1, 1].xaxis.set_tick_params(length = 0)\n",
    "ax[1, 1].set_yticks([0, .8])\n",
    "ax[1, 1].spines['top'].set_visible(False)\n",
    "ax[1, 1].spines['right'].set_visible(False)\n",
    "ax[1, 1].spines['bottom'].set_visible(False)\n",
    "ax[1, 1].spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig_behav.savefig('behavior_state.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural coding\n",
    "\n",
    "Now the IRC is done. We will preprocess the data to prepare for neural analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessing_notebook( idx,\n",
    "#                                  datestring_IRC,\n",
    "#                                  datestring_train,\n",
    "#                                  datestring_data,\n",
    "#                                  datestring_NNagent,\n",
    "#                                  POMDP = False, ENCODING = True, DECODING = False, RECODING = False, NEURAL_NUM = 100\n",
    "#                                )\n",
    "bbelief = np.dstack([dataN_pkl_IRC['belief1_est_MAP'], dataN_pkl_IRC['belief2_est_MAP']])\n",
    "bb = bbelief.reshape(-1, 2)\n",
    "\n",
    "bb_df = DataFrame(bb, columns=['behavior_belief1', 'behavior_belief2'])\n",
    "bb_df.to_csv(path_or_buf='./data/bb_df.csv', index=False)\n",
    "\n",
    "# policy_df = DataFrame(NNpolicy_IRC.T, columns=['NN_IRC_p1', 'NN_IRC_p2', 'NN_IRC_p3', 'NN_IRC_p4', 'NN_IRC_p5'])\n",
    "# policy_df.to_csv(path_or_buf='./data/policy_df.csv', index=False)\n",
    "\n",
    "\n",
    "r = dataN_pkl1['neural_response'][idx, :T, :]\n",
    "r_df = DataFrame(r)  # no colurmn name\n",
    "r_df.to_csv(path_or_buf='./data/r_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing_notebook( idx,\n",
    "                                 datestring_IRC,\n",
    "                                 datestring_train,\n",
    "                                 datestring_data,\n",
    "                                 datestring_NNagent,\n",
    "                                 POMDP = False, ENCODING = False, DECODING = True, RECODING = True, NEURAL_NUM = 100\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./neural_encoding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./neural_recoding_KRR.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./neural_decoding_LR.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
